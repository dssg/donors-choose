config_version: 'v7'

model_comment: 'triage demo'

random_seed: 1995

temporal_config:

    # first date our feature data is good
    feature_start_time: '2000-01-01'
    feature_end_time: '2013-06-01'

    # first date our label data is good
    # donorschoose: as far back as we have good donation data
    label_start_time: '2011-09-02'
    label_end_time: '2013-06-01'

    model_update_frequency: '4month'

    # length of time defining a test set
    test_durations: ['3month']
    # defines how far back a training set reaches
    max_training_histories: ['1y']

    # we sample every day, since new projects are posted
    # every day
    training_as_of_date_frequencies: ['1day']
    test_as_of_date_frequencies: ['1day']
    
    # like our project timeout
    training_label_timespans: ['4month']
    test_label_timespans: ['4month']
    

cohort_config:
  query: |
    SELECT distinct(entity_id), date_posted as as_of_date
      FROM optimized.projects_sampled_temp
    WHERE date_posted = '{as_of_date}'::date - interval '1day'

label_config:
  query: |
        WITH donation_totals AS 
            (SELECT projects_sampled_temp.entity_id, 
            sum(case when donation_to_project is null then 0 else donation_to_project end) as total_donations, 
            total_asking_price AS total_price
            FROM optimized.projects_sampled_temp 
            LEFT JOIN optimized.donations_sampled_temp ON 
                (donations_sampled_temp.entity_id = projects_sampled_temp.entity_id
                    and donations_sampled_temp.donation_timestamp < (projects_sampled_temp.date_posted + interval '{label_timespan}'))
            WHERE projects_sampled_temp.date_posted = '{as_of_date}'::date - interval '1day'
            GROUP BY projects_sampled_temp.entity_id, projects_sampled_temp.total_asking_price)
        SELECT entity_id,
        (total_donations < total_price)::int AS outcome  
        FROM optimized.projects_sampled_temp
        RIGHT JOIN donation_totals using(entity_id)

  name: 'quickstart_label'


feature_aggregations:
  -
    prefix: 'project_features'
    from_obj: 'optimized.projects_sampled_temp'
    knowledge_date_column: 'date_posted'

    aggregates_imputation:
      all:
        type: 'zero'

    categoricals_imputation:
      all:
        type: 'null_category'          

    categoricals:
#       -
#         column: 'school_metro'
#         metrics:
#           - 'sum' 
#         choice_query: 'select distinct school_metro from optimized.projects'
      -
        column: 'resource_type'
        metrics:
          - 'max' 
        choice_query: 'select distinct resource_type from optimized.projects'
#       -
#         column: 'poverty_level'
#         metrics:
#           - 'max' 
#         choice_query: 'select distinct left(poverty_level, 8) from optimized.projects'
#       -
#         column: 'grade_level'
#         metrics:
#           - 'sum' 
#         choice_query: 'select distinct grade_level from optimized.projects'
#       -
#         column: 'teacher_prefix'
#         metrics:
#           - 'sum' 
#         choice_query: 'select distinct teacher_prefix from optimized.projects'
#       -
#         column: 'school_state'
#         metrics:
#           - 'sum' 
#         choice_query: 'select distinct school_state from optimized.projects'
    
    aggregates:
      -
        quantity: 'total_asking_price'
        metrics:
          - 'sum'
      
    # Since our time-aggregate features are precomputed, feature interval is 
    # irrelvant. We keep 'all' as a default.
    intervals: ['all'] 
    groups: ['entity_id']

#   -
#     prefix: 'resources_features'
#     from_obj: 'optimized.resources'
#     knowledge_date_column: 'date_posted'
    
#     aggregates_imputation:
#       all:
#         type: 'zero'
    
#     aggregates:
#       -
#         quantity: 'item_unit_price'
#         metrics:
#           - 'sum'
#       -
#         quantity: 'item_quantity'
#         metrics:
#           - 'sum'
#     intervals: ['all']
#     groups: ['entity_id']
  
#   -
#     prefix: 'essay_features'
#     from_obj: 'optimized.essays'
#     knowledge_date_column: 'date_posted'

#     aggregates_imputation:
#       all:
#         type: 'zero'

#     aggregates:
#       -
#         quantity: 'length(essay)::int'
#         metrics:
#           - 'sum'
#     intervals: ['all']
#     groups: ['entity_id']

  -
    prefix: 'donation_features'
    from_obj: 'optimized.time_series_features'
    knowledge_date_column: 'date_posted'

    aggregates_imputation:
      all:
        type: 'constant'
        value: 0 # for testing

    aggregates:
      - # proportion of fully funded projects posted within the last year at the same district
        quantity: 'district_funding_rate_1yr'
        metrics:
          - 'max'
      - # average donations per project posted within the last year at the same district
        quantity: 'district_avg_donations_1yr'
        metrics:
          - 'max'
#       - # proportion of fully funded projects posted within the last two years at the same district
#         quantity: 'district_funding_rate_2yr'
#         metrics:
#           - 'sum'
#       - # average donations per project posted within the two years at the same district
#         quantity: 'district_avg_donations_2yr'
#         metrics:
#           - 'sum'

#         # teachers
#       - # proportion of fully funded projects posted within the last year by the same teacher
#         quantity: 'teacher_funding_rate_1yr'
#         metrics:
#           - 'sum'
#       - # average donations per project posted within the last year by the same teacher
#         quantity: 'teacher_avg_donations_1yr'
#         metrics:
#           - 'sum'
#       - # proportion of fully funded projects posted within the last two years by the same teacher
#         quantity: 'teacher_funding_rate_2yr'
#         metrics:
#           - 'sum'
#       - # average donations per project posted within the two years by the same teacher
#         quantity: 'teacher_avg_donations_2yr'
#         metrics:
#           - 'sum'

#         # zip
#       - # proportion of fully funded projects posted within the last year in the same zip code
#         quantity: 'zip_funding_rate_1yr'
#         metrics:
#           - 'sum'
#       - # average donations per project posted within the last year in the same zip code
#         quantity: 'zip_avg_donations_1yr'
#         metrics:
#           - 'sum'
#       - # proportion of fully funded projects posted within the last two years in the same zip code
#         quantity: 'zip_funding_rate_2yr'
#         metrics:
#           - 'sum'
#       - # average donations per project posted within the two years in the same zip code
#         quantity: 'zip_avg_donations_2yr'
#         metrics:
#           - 'sum'

    intervals: ['all']
    groups: ['entity_id']
      
# grid_config:
#   'sklearn.ensemble.RandomForestClassifier':
#       n_estimators: [1000, 2500, 5000, 10000]
#       max_depth: [2, 5, 10, 50]
#       max_features: [3, 5, 8, 10, 12, 15, 'auto', 'log2']
#       min_samples_split: [2, 10, 25, 50]
#   'sklearn.linear_model.LogisticRegression':
#       max_iter: [10000]
#       penalty: ['l1', 'l2']
#       C: [0.001, 0.01, 0.1, 0.5, 1, 2, 10]
#       solver: ['saga']
#   'sklearn.tree.DecisionTreeClassifier':
#       max_depth: [2, 5, 10, 50]
#       max_features: [null, 2, 5, 10, 'auto', 'log2']
#       min_samples_split: [2, 10, 25, 50]
#       random_state: [0]
#   'sklearn.dummy.DummyClassifier':
#       # baseline, predicts base rate
#       strategy: ['prior']
#   'triage.component.catwalk.baselines.rankers.PercentileRankOneFeature':
#       feature: ['project_features_entity_id_all_total_asking_price_imp']

grid_config:
    'sklearn.ensemble.RandomForestClassifier':
      n_estimators: [150]
      max_depth: [50]
      min_samples_split: [25]
    
    'sklearn.tree.DecisionTreeClassifier':
      max_depth: [10]
      max_features: [null]
      min_samples_split: [25]
      
    'triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression':
        C: [0.01]
        penalty: ['l1']
    
    'triage.component.catwalk.baselines.rankers.PercentileRankOneFeature':
      feature: ['project_features_entity_id_all_total_asking_price_sum']
      descend: [False]


scoring:
    testing_metric_groups:
        -
          metrics: [precision@]
          thresholds:
          percentiles: [1, 2, 3, 4, 5, 6, 7, 8, 9, 
              10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
              20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 
              30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 
              40, 41, 42, 43, 44, 45, 46, 47, 48, 49,
              50, 51, 52, 53, 54, 55, 56, 57, 58, 59,
              60, 61, 62, 63, 64, 65, 66, 67, 68, 69,
              70, 71, 72, 73, 74, 75, 76, 77, 78, 79,
              80, 81, 82, 83, 84, 85, 86, 87, 88, 89,
              90, 91, 92, 93, 94, 95, 96, 97, 98, 99,
              100]
          top_n: []
          
individual_importance:
    methods: [] # empty list means don't calculate individual importances
    n_ranks: 1 

