{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Narrowing down DonorsChoose for a quick triage demo** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from triage.experiments import MultiCoreExperiment\n",
    "from triage import create_engine\n",
    "from sqlalchemy.engine.url import URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB Conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('database.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    db_url = URL(\n",
    "        'postgres',\n",
    "        host=config['host'],\n",
    "        username=config['user'],\n",
    "        database=config['db'],\n",
    "        password=config['password'],\n",
    "        port=config['port'],\n",
    "    )\n",
    "\n",
    "    conn = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Create a sampled down version of the donors choose data\n",
    "- Create a handful of features to demonstrate the feature engineering capabilities of triage\n",
    "- run a small model grid with three models (Logit, DT, RF)\n",
    "- Target is to get the triage run finished in a few mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Sampled down version of donors\n",
    "\n",
    "For testing, I'm creating a new projects table that contains prjects from ~10% schools in the dataset and changing the cohort query read from the \"new\" projects table.\n",
    "\n",
    "Note -- There are about 57000 different schools. We can change how we sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7f05ed421190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "\n",
    "    drop table if exists optimized.projects_sampled_temp; \n",
    "    drop table if exists optimized.donations_sampled_temp;\n",
    "    drop table if exists optimized.precomputed_features_sampled;\n",
    "    \n",
    "    -- Sampling schools and projects\n",
    "    create table optimized.projects_sampled_temp as (\n",
    "        with schools as (\n",
    "        select \n",
    "            distinct schoolid \n",
    "        from optimized.projects\n",
    "    ),\n",
    "    sampled_schools as (\n",
    "        select * from schools order by random() limit 1425\n",
    "    )\n",
    "    select \n",
    "        *\n",
    "    from sampled_schools join optimized.projects using(schoolid)\n",
    "    );\n",
    "    \n",
    "    \n",
    "    -- Fetching all donations from the sampled projects\n",
    "    create table optimized.donations_sampled_temp as (\n",
    "        select b.* from optimized.projects_sampled_temp a join optimized.donations b using(entity_id)\n",
    "    ); \n",
    "    \n",
    "    -- Fetching the precomputed features for the sampled projects\n",
    "    create table optimized.precomputed_features_sampled as (\n",
    "        select * from optimized. projects_sampled_temp join optimized.time_series_features using(entity_id, date_posted) \n",
    "    );    \n",
    "\"\"\"\n",
    "\n",
    "conn.execute(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triage config\n",
    "\n",
    "currently contains six features. Two static and two dynamic. But, since the dynamic features are precomputed, from a demo perspective they appear static. We could see how long it takes to compute the features on-the-fly maybe with indexed tables. (currently the optimized donations table doesn't have any indexes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('demo_config.yaml', 'r') as f:\n",
    "    triage_config = yaml.safe_load(f)\n",
    "    \n",
    "# TODO -- replace with an S3 bucket\n",
    "project_folder = '/mnt/data/experiment_data/donors/demo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-09-20 15:44:58\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mMatrices and trained models will be saved in /mnt/data/experiment_data/donors/demo/\u001b[0m\n",
      "\u001b[32m2021-09-20 15:44:58\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mReplace flag is set to true. Matrices, models, evaluations and predictions (if exist) will be replaced\u001b[0m\n",
      "\u001b[32m2021-09-20 15:44:58\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mSave predictions flag is set to false. Predictions won't be stored in the predictions table. This will decrease both the running time of an experiment and also decrease the space needed in the db\u001b[0m\n",
      "\u001b[32m2021-09-20 15:44:58\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mUsing random seed [1995] for running the experiment\u001b[0m\n",
      "\u001b[32m2021-09-20 15:44:58\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mbias_audit_config missing in the configuration file or unrecognized. Without protected groups, you will not audit your models for bias and fairness.\u001b[0m\n",
      "\u001b[32m2021-09-20 15:44:58\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mscoring.subsets missing in the configuration file or unrecognized. No subsets will be generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "experiment = MultiCoreExperiment(\n",
    "    config=triage_config,\n",
    "    db_engine=conn,\n",
    "    n_processes=2,\n",
    "    n_db_processes=2,\n",
    "    project_path=project_folder,\n",
    "    replace=True,\n",
    "    save_predictions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-09-20 15:45:01\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mSection: scoring - No training_metric_groups configured. If training set evaluation metrics are desired, they must be added\u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:01\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mExperiment validation ran to completion with no errors\u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:01\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mComputed and stored temporal split definitions\u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:01\u001b[0m - \u001b[1;30m   INFO\u001b[0m Setting up cohort\n",
      "\u001b[32m2021-09-20 15:45:04\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mCohort setted up in the table cohort_all_entities_1c7e6ce13aaaa12abe16964d559707a9 successfully\u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Setting up labels\n",
      "\u001b[32m2021-09-20 15:45:19\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mLabels setted up in the table labels_quickstart_label_76cc17d016ee3084aed0425d67801eb1 successfully \u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:19\u001b[0m - \u001b[1;30m   INFO\u001b[0m Creating features tables (before imputation) \n",
      "\u001b[32m2021-09-20 15:45:19\u001b[0m - \u001b[1;30m   INFO\u001b[0m Creating collate aggregations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasun/.pyenv/versions/aclu/lib/python3.7/site-packages/sqlalchemy/sql/base.py:302: SAWarning: Can't validate argument 'autoload_from'; can't locate any SQLAlchemy dialect named 'autoload'\n",
      "  % (k, dialect_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-09-20 15:45:20\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mStarting Feature aggregation\u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:20\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mImputed feature table project_features_aggregation_imputed looks good, skipping feature building!\u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:21\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mImputed feature table teachr_funding_aggregation_imputed looks good, skipping feature building!\u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:21\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mImputed feature table donation_features_aggregation_imputed looks good, skipping feature building!\u001b[0m\n",
      "\u001b[32m2021-09-20 15:45:21\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing query tasks with 2 processes\n",
      "\u001b[32m2021-09-20 15:45:21\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_entity_id\n",
      "\u001b[32m2021-09-20 15:45:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:24\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:24\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:24\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:24\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:24\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:25\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:25\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:25\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:25\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 20, failures: 0\n",
      "\u001b[32m2021-09-20 15:45:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_entity_id completed\n",
      "\u001b[32m2021-09-20 15:45:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_aggregation\n",
      "\u001b[32m2021-09-20 15:45:33\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 15:45:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_aggregation completed\n",
      "\u001b[32m2021-09-20 15:45:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for teachr_funding_entity_id\n",
      "\u001b[32m2021-09-20 15:45:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:37\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:37\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:38\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:38\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:39\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:39\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:40\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:41\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:42\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:42\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:43\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:43\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:44\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:44\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:45\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:46\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:46\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:47\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:45:47\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 20, failures: 0\n",
      "\u001b[32m2021-09-20 15:45:48\u001b[0m - \u001b[1;30m   INFO\u001b[0m teachr_funding_entity_id completed\n",
      "\u001b[32m2021-09-20 15:45:48\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for teachr_funding_aggregation\n",
      "\u001b[32m2021-09-20 15:46:00\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m teachr_funding_aggregation completed\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for donation_features_entity_id\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 15:46:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 20, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m donation_features_entity_id completed\n",
      "\u001b[32m2021-09-20 15:46:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for donation_features_aggregation\n",
      "\u001b[32m2021-09-20 15:46:09\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m donation_features_aggregation completed\n",
      "\u001b[32m2021-09-20 15:46:11\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mFeatures (before imputation) were stored in the tables \"features\".\"project_features_aggregation\",\"features\".\"teachr_funding_aggregation\",\"features\".\"donation_features_aggregation\" successfully\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Imputing missing values in features\n",
      "\u001b[32m2021-09-20 15:46:11\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mStarting Feature imputation\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing query tasks with 2 processes\n",
      "\u001b[32m2021-09-20 15:46:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_aggregation_imputed\n",
      "\u001b[32m2021-09-20 15:46:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_aggregation_imputed completed\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for teachr_funding_aggregation_imputed\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m teachr_funding_aggregation_imputed completed\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for donation_features_aggregation_imputed\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m donation_features_aggregation_imputed completed\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mImputed features were stored in the tables \"features\".\"project_features_aggregation_imputed\",\"features\".\"teachr_funding_aggregation_imputed\",\"features\".\"donation_features_aggregation_imputed\" successfully\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mFound 3 total feature subsets\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Building matrices\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mIt is necessary to build 6 matrices\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallel matrix building: 6 matrices, 2 processes\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix b0c3b7a2420070cec525e0d5beb13fec saved in /mnt/data/experiment_data/donors/demo/matrices/b0c3b7a2420070cec525e0d5beb13fec.csv.gz\n",
      "\u001b[32m2021-09-20 15:46:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix ef474add1a1fde55d178ff2f90dc0267 saved in /mnt/data/experiment_data/donors/demo/matrices/ef474add1a1fde55d178ff2f90dc0267.csv.gz\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix da6178814ccfcaef6b726c72fe189146 saved in /mnt/data/experiment_data/donors/demo/matrices/da6178814ccfcaef6b726c72fe189146.csv.gz\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb saved in /mnt/data/experiment_data/donors/demo/matrices/0bb3280efd4a2966c5aa9e2a2a35d3cb.csv.gz\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 3eab2fda852fb35c439e048855f9f804 saved in /mnt/data/experiment_data/donors/demo/matrices/3eab2fda852fb35c439e048855f9f804.csv.gz\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix feb9df96036176bb6d80032ce7015fc6 saved in /mnt/data/experiment_data/donors/demo/matrices/feb9df96036176bb6d80032ce7015fc6.csv.gz\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 6, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mMatrices were stored in /mnt/data/experiment_data/donors/demo//matrices successfully\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallel subset creation: 0 subsets, 2 processes\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups will not be created\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mSplit train/test tasks into three task batches. - each batch has models from all splits\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 1: Baselines or simple classifiers (e.g. DecisionTree, SLR) (9 tasks total)\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 2: Heavyweight classifiers with n_jobs set to -1. (0 tasks total)\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 3: All classifiers not found in one of the other batches (e.g. gradient boosting). (3 tasks total)\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m 4 models groups will be trained, tested and evaluated\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Training, testing and evaluating models\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34m3 train/test tasks found.\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallelizable batch train/testing with 9 tasks, 2 processes\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [40d2e38b07a6bc0c08bf54e1b8a32876] on train matrix b0c3b7a2420070cec525e0d5beb13fec\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [7c70f18fd0e05cfd754efdf7691f8fd3] on train matrix b0c3b7a2420070cec525e0d5beb13fec\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 49, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 50, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 49: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [40d2e38b07a6bc0c08bf54e1b8a32876] on train matrix b0c3b7a2420070cec525e0d5beb13fec. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:13\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 50: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [7c70f18fd0e05cfd754efdf7691f8fd3] on train matrix b0c3b7a2420070cec525e0d5beb13fec. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:14\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 49 on test matrix ef474add1a1fde55d178ff2f90dc0267  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:14\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:14\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:14\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 50 on test matrix ef474add1a1fde55d178ff2f90dc0267  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:14\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:21\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 49 evaluation on test matrix ef474add1a1fde55d178ff2f90dc0267 completed.\n",
      "\u001b[32m2021-09-20 15:46:21\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 49 on train matrix b0c3b7a2420070cec525e0d5beb13fec  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:21\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 49 evaluation on train matrix b0c3b7a2420070cec525e0d5beb13fec completed.\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [723e2a507c5923c8637084713ba8a119] on train matrix b0c3b7a2420070cec525e0d5beb13fec\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 50 evaluation on test matrix ef474add1a1fde55d178ff2f90dc0267 completed.\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 50 on train matrix b0c3b7a2420070cec525e0d5beb13fec  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mFound model 39, updating non-unique attributes\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 39: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [723e2a507c5923c8637084713ba8a119] on train matrix b0c3b7a2420070cec525e0d5beb13fec. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 39 on test matrix ef474add1a1fde55d178ff2f90dc0267  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 50 evaluation on train matrix b0c3b7a2420070cec525e0d5beb13fec completed.\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [82a2d6c3f1e17a57dbcfc6fd0f41438a] on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 51, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 51: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [82a2d6c3f1e17a57dbcfc6fd0f41438a] on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 51 on test matrix da6178814ccfcaef6b726c72fe189146  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:22\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 39 evaluation on test matrix ef474add1a1fde55d178ff2f90dc0267 completed.\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 39 on train matrix b0c3b7a2420070cec525e0d5beb13fec  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 39 evaluation on train matrix b0c3b7a2420070cec525e0d5beb13fec completed.\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [2dee2f5a9253aed8f9fd10d5260a94bb] on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 52, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 52: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [2dee2f5a9253aed8f9fd10d5260a94bb] on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 52 on test matrix da6178814ccfcaef6b726c72fe189146  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:23\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 51 evaluation on test matrix da6178814ccfcaef6b726c72fe189146 completed.\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 51 on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 51 evaluation on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb completed.\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [2dba81098d2dc9b4b17e61aab8e61a91] on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mFound model 42, updating non-unique attributes\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 42: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [2dba81098d2dc9b4b17e61aab8e61a91] on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 42 on test matrix da6178814ccfcaef6b726c72fe189146  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:31\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 52 evaluation on test matrix da6178814ccfcaef6b726c72fe189146 completed.\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 52 on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 52 evaluation on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb completed.\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 42 evaluation on test matrix da6178814ccfcaef6b726c72fe189146 completed.\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 42 on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [006710d14c11db67027350cab9c7e5c2] on train matrix feb9df96036176bb6d80032ce7015fc6\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 53, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 53: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [006710d14c11db67027350cab9c7e5c2] on train matrix feb9df96036176bb6d80032ce7015fc6. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 42 evaluation on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb completed.\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [e050bf9ce3650b446fa397c459c6d3df] on train matrix feb9df96036176bb6d80032ce7015fc6\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 53 on test matrix 3eab2fda852fb35c439e048855f9f804  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 54, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:32\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 54: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [e050bf9ce3650b446fa397c459c6d3df] on train matrix feb9df96036176bb6d80032ce7015fc6. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:33\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:33\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 54 on test matrix 3eab2fda852fb35c439e048855f9f804  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:33\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:38\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 54 evaluation on test matrix 3eab2fda852fb35c439e048855f9f804 completed.\n",
      "\u001b[32m2021-09-20 15:46:38\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 54 on train matrix feb9df96036176bb6d80032ce7015fc6  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:38\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:39\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 54 evaluation on train matrix feb9df96036176bb6d80032ce7015fc6 completed.\n",
      "\u001b[32m2021-09-20 15:46:39\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [7ac5d24a246a4b5bd125105626483c00] on train matrix feb9df96036176bb6d80032ce7015fc6\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:39\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mFound model 45, updating non-unique attributes\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:39\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 45: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [7ac5d24a246a4b5bd125105626483c00] on train matrix feb9df96036176bb6d80032ce7015fc6. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:39\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 45 on test matrix 3eab2fda852fb35c439e048855f9f804  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:39\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 45 evaluation on test matrix 3eab2fda852fb35c439e048855f9f804 completed.\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 45 on train matrix feb9df96036176bb6d80032ce7015fc6  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 53 evaluation on test matrix 3eab2fda852fb35c439e048855f9f804 completed.\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 53 on train matrix feb9df96036176bb6d80032ce7015fc6  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 45 evaluation on train matrix feb9df96036176bb6d80032ce7015fc6 completed.\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 53 evaluation on train matrix feb9df96036176bb6d80032ce7015fc6 completed.\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 9, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting serial batch train/testing with {len(batch.tasks)} tasks\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallelizable batch train/testing with 3 tasks, 2 processes\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [67fe264b9de3345f301bcf5be4a807e4] on train matrix b0c3b7a2420070cec525e0d5beb13fec\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:40\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [033e18f067dd5bb4401c89ab9b8d5faf] on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:41\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mFound model 46, updating non-unique attributes\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:41\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 46: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [67fe264b9de3345f301bcf5be4a807e4] on train matrix b0c3b7a2420070cec525e0d5beb13fec. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:41\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 46 on test matrix ef474add1a1fde55d178ff2f90dc0267  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:41\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:41\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mFound model 47, updating non-unique attributes\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:41\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 47: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [033e18f067dd5bb4401c89ab9b8d5faf] on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:41\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 47 on test matrix da6178814ccfcaef6b726c72fe189146  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:41\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:42\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 46 evaluation on test matrix ef474add1a1fde55d178ff2f90dc0267 completed.\n",
      "\u001b[32m2021-09-20 15:46:42\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 46 on train matrix b0c3b7a2420070cec525e0d5beb13fec  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:42\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:42\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 46 evaluation on train matrix b0c3b7a2420070cec525e0d5beb13fec completed.\n",
      "\u001b[32m2021-09-20 15:46:42\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [460ab3cda1e3c0cc45d9915ba94ee3cb] on train matrix feb9df96036176bb6d80032ce7015fc6\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:42\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 47 evaluation on test matrix da6178814ccfcaef6b726c72fe189146 completed.\n",
      "\u001b[32m2021-09-20 15:46:42\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 47 on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:42\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:43\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 47 evaluation on train matrix 0bb3280efd4a2966c5aa9e2a2a35d3cb completed.\n",
      "\u001b[32m2021-09-20 15:46:43\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mFound model 48, updating non-unique attributes\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:43\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 48: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [460ab3cda1e3c0cc45d9915ba94ee3cb] on train matrix feb9df96036176bb6d80032ce7015fc6. \u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:43\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 48 on test matrix 3eab2fda852fb35c439e048855f9f804  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:43\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:44\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 48 evaluation on test matrix 3eab2fda852fb35c439e048855f9f804 completed.\n",
      "\u001b[32m2021-09-20 15:46:44\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 48 on train matrix feb9df96036176bb6d80032ce7015fc6  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:44\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:45\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 48 evaluation on train matrix feb9df96036176bb6d80032ce7015fc6 completed.\n",
      "\u001b[32m2021-09-20 15:46:45\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 3, failures: 0\n",
      "\u001b[32m2021-09-20 15:46:45\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTraining, testing and evaluatiog models completed\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:45\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mAll matrices that were supposed to be build were built. Awesome!\u001b[0m\n",
      "\u001b[32m2021-09-20 15:46:45\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mAll models that were supposed to be trained were trained. Awesome!\u001b[0m\n",
      "CPU times: user 4.15 s, sys: 1.11 s, total: 5.26 s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f48d28dd088aeeb6a87ab9f3f9f95e5a'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"select experiment_hash from triage_metadata.experiment_runs order by start_time desc limit 1;\"\n",
    "\n",
    "experiment_hash = pd.read_sql(q, conn)['experiment_hash'].iloc[0]\n",
    "experiment_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012-11-01'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "    select \n",
    "        to_char(max(train_end_time), 'YYYY-MM-DD') as last_time\n",
    "    from triage_metadata.experiment_models\n",
    "    join triage_metadata.models using(model_hash)\n",
    "    where experiment_hash = '{experiment_hash}'\n",
    "\"\"\".format(experiment_hash=experiment_hash)\n",
    "\n",
    "last_train_end_time = pd.read_sql(q, conn)['last_time'].iloc[0]\n",
    "last_train_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_type</th>\n",
       "      <th>metric</th>\n",
       "      <th>parameter</th>\n",
       "      <th>best_value</th>\n",
       "      <th>worst_value</th>\n",
       "      <th>stochastic_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>sklearn.tree.DecisionTreeClassifier</td>\n",
       "      <td>precision@</td>\n",
       "      <td>15_pct</td>\n",
       "      <td>0.524752</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.490759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>triage.component.catwalk.estimators.classifier...</td>\n",
       "      <td>precision@</td>\n",
       "      <td>15_pct</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.366337</td>\n",
       "      <td>0.436634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>triage.component.catwalk.baselines.rankers.Per...</td>\n",
       "      <td>precision@</td>\n",
       "      <td>15_pct</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.465347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>sklearn.ensemble.RandomForestClassifier</td>\n",
       "      <td>precision@</td>\n",
       "      <td>15_pct</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.504950</td>\n",
       "      <td>0.504950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id                                         model_type      metric  \\\n",
       "0        53                sklearn.tree.DecisionTreeClassifier  precision@   \n",
       "1        54  triage.component.catwalk.estimators.classifier...  precision@   \n",
       "2        45  triage.component.catwalk.baselines.rankers.Per...  precision@   \n",
       "3        48            sklearn.ensemble.RandomForestClassifier  precision@   \n",
       "\n",
       "  parameter  best_value  worst_value  stochastic_value  \n",
       "0    15_pct    0.524752     0.455446          0.490759  \n",
       "1    15_pct    0.495050     0.366337          0.436634  \n",
       "2    15_pct    0.465347     0.465347          0.465347  \n",
       "3    15_pct    0.504950     0.504950          0.504950  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "    select \n",
    "        model_id, model_type, metric, parameter, best_value, worst_value, stochastic_value\n",
    "    from triage_metadata.experiment_models\n",
    "    join triage_metadata.models using(model_hash)\n",
    "    join test_results.evaluations using(model_id)\n",
    "    where experiment_hash = '{experiment_hash}' and train_end_time='{last_split}' \n",
    "    and metric='precision@' and parameter='15_pct'\n",
    "\"\"\".format(\n",
    "    experiment_hash = experiment_hash,\n",
    "    last_split=last_train_end_time\n",
    ")\n",
    "\n",
    "evals = pd.read_sql(q, conn)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aclu",
   "language": "python",
   "name": "aclu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
