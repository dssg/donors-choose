{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Narrowing down DonorsChoose for a quick triage demo** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from triage.experiments import MultiCoreExperiment\n",
    "from triage import create_engine\n",
    "from sqlalchemy.engine.url import URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DB Conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('database.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    db_url = URL(\n",
    "        'postgres',\n",
    "        host=config['host'],\n",
    "        username=config['user'],\n",
    "        database=config['db'],\n",
    "        password=config['pass'],\n",
    "        port=config['port'],\n",
    "    )\n",
    "\n",
    "    conn = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- Create a sampled down version of the donors choose data\n",
    "- Create a handful of features to demonstrate the feature engineering capabilities of triage\n",
    "- run a small model grid with three models (Logit, DT, RF)\n",
    "- Target is to get the triage run finished in a few mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Sampled down version of donors\n",
    "\n",
    "For testing, I'm creating a new projects table that contains prjects from ~10% schools in the dataset and changing the cohort query read from the \"new\" projects table.\n",
    "\n",
    "Note -- There are about 57000 different schools. We can change how we sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7f697e0cf150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "\n",
    "    drop table if exists optimized.projects_sampled_temp; \n",
    "    drop table if exists optimized.donations_sampled_temp;\n",
    "    drop table if exists optimized.precomputed_features_sampled;\n",
    "    \n",
    "    -- Sampling schools and projects\n",
    "    create table optimized.projects_sampled_temp as (\n",
    "        with schools as (\n",
    "        select \n",
    "            distinct schoolid \n",
    "        from optimized.projects\n",
    "    ),\n",
    "    sampled_schools as (\n",
    "        select * from schools order by random() limit 1425\n",
    "    )\n",
    "    select \n",
    "        *\n",
    "    from sampled_schools join optimized.projects using(schoolid)\n",
    "    );\n",
    "    \n",
    "    \n",
    "    -- Fetching all donations from the sampled projects\n",
    "    create table optimized.donations_sampled_temp as (\n",
    "        select b.* from optimized.projects_sampled_temp a join optimized.donations b using(entity_id)\n",
    "    ); \n",
    "    \n",
    "    -- Fetching the precomputed features for the sampled projects\n",
    "    create table optimized.precomputed_features_sampled as (\n",
    "        select * from optimized. projects_sampled_temp join optimized.time_series_features using(entity_id, date_posted) \n",
    "    );    \n",
    "\"\"\"\n",
    "\n",
    "conn.execute(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triage config\n",
    "\n",
    "Contains six features. Two static, two time-series but precomputed, two time-series calculated during triage run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('demo_config.yaml', 'r') as f:\n",
    "    triage_config = yaml.safe_load(f)\n",
    "    \n",
    "# TODO -- replace with an S3 bucket\n",
    "project_folder = '/mnt/data/experiment_data/donors/demo/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-09-20 16:32:38\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mMatrices and trained models will be saved in /mnt/data/experiment_data/donors/demo/\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:38\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mReplace flag is set to true. Matrices, models, evaluations and predictions (if exist) will be replaced\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:38\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mSave predictions flag is set to false. Predictions won't be stored in the predictions table. This will decrease both the running time of an experiment and also decrease the space needed in the db\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:38\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mUsing random seed [1995] for running the experiment\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:39\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mbias_audit_config missing in the configuration file or unrecognized. Without protected groups, you will not audit your models for bias and fairness.\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:39\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mscoring.subsets missing in the configuration file or unrecognized. No subsets will be generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "experiment = MultiCoreExperiment(\n",
    "    config=triage_config,\n",
    "    db_engine=conn,\n",
    "    n_processes=2,\n",
    "    n_db_processes=2,\n",
    "    project_path=project_folder,\n",
    "    replace=True,\n",
    "    save_predictions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-09-20 16:32:43\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mSection: scoring - No training_metric_groups configured. If training set evaluation metrics are desired, they must be added\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:43\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mExperiment validation ran to completion with no errors\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:43\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mComputed and stored temporal split definitions\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:43\u001b[0m - \u001b[1;30m   INFO\u001b[0m Setting up cohort\n",
      "\u001b[32m2021-09-20 16:32:46\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mCohort setted up in the table cohort_all_entities_1c7e6ce13aaaa12abe16964d559707a9 successfully\u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:46\u001b[0m - \u001b[1;30m   INFO\u001b[0m Setting up labels\n",
      "\u001b[32m2021-09-20 16:32:59\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mLabels setted up in the table labels_quickstart_label_76cc17d016ee3084aed0425d67801eb1 successfully \u001b[0m\n",
      "\u001b[32m2021-09-20 16:32:59\u001b[0m - \u001b[1;30m   INFO\u001b[0m Creating features tables (before imputation) \n",
      "\u001b[32m2021-09-20 16:32:59\u001b[0m - \u001b[1;30m   INFO\u001b[0m Creating collate aggregations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kasun/.pyenv/versions/triage-demo/lib/python3.7/site-packages/sqlalchemy/sql/base.py:302: SAWarning: Can't validate argument 'autoload_from'; can't locate any SQLAlchemy dialect named 'autoload'\n",
      "  % (k, dialect_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-09-20 16:33:00\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mStarting Feature aggregation\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:00\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mImputed feature table project_features_aggregation_imputed did not contain rows from the entire cohort, need to rebuild features\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:01\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mImputed feature table teachr_funding_aggregation_imputed did not contain rows from the entire cohort, need to rebuild features\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:01\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mImputed feature table donation_features_aggregation_imputed did not contain rows from the entire cohort, need to rebuild features\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:01\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing query tasks with 2 processes\n",
      "\u001b[32m2021-09-20 16:33:01\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_entity_id\n",
      "\u001b[32m2021-09-20 16:33:01\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:01\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 20, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_entity_id completed\n",
      "\u001b[32m2021-09-20 16:33:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_aggregation\n",
      "\u001b[32m2021-09-20 16:33:08\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:10\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_aggregation completed\n",
      "\u001b[32m2021-09-20 16:33:10\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for teachr_funding_entity_id\n",
      "\u001b[32m2021-09-20 16:33:10\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:10\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:13\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:14\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:15\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:16\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 20, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m teachr_funding_entity_id completed\n",
      "\u001b[32m2021-09-20 16:33:17\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for teachr_funding_aggregation\n",
      "\u001b[32m2021-09-20 16:33:25\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m teachr_funding_aggregation completed\n",
      "\u001b[32m2021-09-20 16:33:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for donation_features_entity_id\n",
      "\u001b[32m2021-09-20 16:33:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:26\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:27\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m Beginning insert batch\n",
      "\u001b[32m2021-09-20 16:33:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 20, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m donation_features_entity_id completed\n",
      "\u001b[32m2021-09-20 16:33:28\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for donation_features_aggregation\n",
      "\u001b[32m2021-09-20 16:33:32\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m donation_features_aggregation completed\n",
      "\u001b[32m2021-09-20 16:33:34\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mFeatures (before imputation) were stored in the tables \"features\".\"project_features_aggregation\",\"features\".\"teachr_funding_aggregation\",\"features\".\"donation_features_aggregation\" successfully\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m Imputing missing values in features\n",
      "\u001b[32m2021-09-20 16:33:34\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mStarting Feature imputation\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing query tasks with 2 processes\n",
      "\u001b[32m2021-09-20 16:33:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for project_features_aggregation_imputed\n",
      "\u001b[32m2021-09-20 16:33:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:34\u001b[0m - \u001b[1;30m   INFO\u001b[0m project_features_aggregation_imputed completed\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for teachr_funding_aggregation_imputed\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m teachr_funding_aggregation_imputed completed\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Processing features for donation_features_aggregation_imputed\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m donation_features_aggregation_imputed completed\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mImputed features were stored in the tables \"features\".\"project_features_aggregation_imputed\",\"features\".\"teachr_funding_aggregation_imputed\",\"features\".\"donation_features_aggregation_imputed\" successfully\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mFound 1 total feature subsets\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Building matrices\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mIt is necessary to build 6 matrices\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallel matrix building: 6 matrices, 2 processes\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 96b224b8e1497f77156ae38a0250aa73 saved in /mnt/data/experiment_data/donors/demo/matrices/96b224b8e1497f77156ae38a0250aa73.csv.gz\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 43e540def2000416c6b4bc020e4921f7 saved in /mnt/data/experiment_data/donors/demo/matrices/43e540def2000416c6b4bc020e4921f7.csv.gz\n",
      "\u001b[32m2021-09-20 16:33:35\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 690f1ba2c18295a38c06c378f3ec1cdb saved in /mnt/data/experiment_data/donors/demo/matrices/690f1ba2c18295a38c06c378f3ec1cdb.csv.gz\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix 3ba0ca70dcc92f9736ef5e8b97f9737b saved in /mnt/data/experiment_data/donors/demo/matrices/3ba0ca70dcc92f9736ef5e8b97f9737b.csv.gz\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix bd72f652b06c4065a78377932d6d52c1 saved in /mnt/data/experiment_data/donors/demo/matrices/bd72f652b06c4065a78377932d6d52c1.csv.gz\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Matrix cb2b50979f67ed20aa9123ca02455011 saved in /mnt/data/experiment_data/donors/demo/matrices/cb2b50979f67ed20aa9123ca02455011.csv.gz\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 6, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mMatrices were stored in /mnt/data/experiment_data/donors/demo//matrices successfully\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallel subset creation: 0 subsets, 2 processes\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups will not be created\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mSplit train/test tasks into three task batches. - each batch has models from all splits\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 1: Baselines or simple classifiers (e.g. DecisionTree, SLR) (9 tasks total)\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 2: Heavyweight classifiers. (3 tasks total)\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mBatch 3: All classifiers not found in one of the other batches. (0 tasks total)\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m 4 models groups will be trained, tested and evaluated\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Training, testing and evaluating models\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34m3 train/test tasks found.\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallelizable batch train/testing with 9 tasks, 2 processes\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [7e27869cbbf42eb505c5edee68f5f4e4] on train matrix 96b224b8e1497f77156ae38a0250aa73\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [966b4d2ab12e17d4f9e1feea1adbab02] on train matrix 96b224b8e1497f77156ae38a0250aa73\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 67, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 68, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 67: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [7e27869cbbf42eb505c5edee68f5f4e4] on train matrix 96b224b8e1497f77156ae38a0250aa73. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:36\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 68: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [966b4d2ab12e17d4f9e1feea1adbab02] on train matrix 96b224b8e1497f77156ae38a0250aa73. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:37\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 67 on test matrix 43e540def2000416c6b4bc020e4921f7  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:37\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:37\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:37\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 68 on test matrix 43e540def2000416c6b4bc020e4921f7  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:37\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 67 evaluation on test matrix 43e540def2000416c6b4bc020e4921f7 completed.\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 67 on train matrix 96b224b8e1497f77156ae38a0250aa73  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 67 evaluation on train matrix 96b224b8e1497f77156ae38a0250aa73 completed.\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [95e5f4f0c213cb8f5ec7b42f3b2d5539] on train matrix 96b224b8e1497f77156ae38a0250aa73\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 68 evaluation on test matrix 43e540def2000416c6b4bc020e4921f7 completed.\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 68 on train matrix 96b224b8e1497f77156ae38a0250aa73  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 69, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 69: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [95e5f4f0c213cb8f5ec7b42f3b2d5539] on train matrix 96b224b8e1497f77156ae38a0250aa73. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:45\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 68 evaluation on train matrix 96b224b8e1497f77156ae38a0250aa73 completed.\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [585c8bba02ca978dd2f892b82aed8d28] on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 69 on test matrix 43e540def2000416c6b4bc020e4921f7  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 70, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 70: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [585c8bba02ca978dd2f892b82aed8d28] on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 70 on test matrix 690f1ba2c18295a38c06c378f3ec1cdb  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 69 evaluation on test matrix 43e540def2000416c6b4bc020e4921f7 completed.\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 69 on train matrix 96b224b8e1497f77156ae38a0250aa73  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:46\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:47\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 69 evaluation on train matrix 96b224b8e1497f77156ae38a0250aa73 completed.\n",
      "\u001b[32m2021-09-20 16:33:47\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [43eaa1400152385ab3f1e7befbf44ee3] on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:47\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 71, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:47\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:47\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 71: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [43eaa1400152385ab3f1e7befbf44ee3] on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:47\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:47\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 71 on test matrix 690f1ba2c18295a38c06c378f3ec1cdb  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:47\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 71 evaluation on test matrix 690f1ba2c18295a38c06c378f3ec1cdb completed.\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 71 on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 71 evaluation on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b completed.\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [5d0a55b81b9de8ad317d66fa1dfc8df7] on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 72, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 72: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [5d0a55b81b9de8ad317d66fa1dfc8df7] on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 70 evaluation on test matrix 690f1ba2c18295a38c06c378f3ec1cdb completed.\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 72 on test matrix 690f1ba2c18295a38c06c378f3ec1cdb  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 70 on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:54\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 70 evaluation on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b completed.\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [8ead3875912c61fdd0eee32460673bdc] on train matrix cb2b50979f67ed20aa9123ca02455011\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 73, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 73: sklearn.tree.DecisionTreeClassifier({'max_depth': 3, 'max_features': None, 'min_samples_split': 25}) [8ead3875912c61fdd0eee32460673bdc] on train matrix cb2b50979f67ed20aa9123ca02455011. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 73 on test matrix bd72f652b06c4065a78377932d6d52c1  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 72 evaluation on test matrix 690f1ba2c18295a38c06c378f3ec1cdb completed.\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 72 on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:55\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:56\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 72 evaluation on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b completed.\n",
      "\u001b[32m2021-09-20 16:33:56\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [83480417ac79231ea5bcbc5f0a2cd4e9] on train matrix cb2b50979f67ed20aa9123ca02455011\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:56\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 74, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:56\u001b[0m - \u001b[1;30mWARNING\u001b[0m \u001b[33mThe selected algorithm, doesn't support a standard way of calculate the importance of each feature used. Falling back to ad-hoc methods (e.g. in LogisticRegression we will return Odd Ratios instead coefficients)\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:56\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 74: triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression({'C': 0.1, 'penalty': 'l1'}) [83480417ac79231ea5bcbc5f0a2cd4e9] on train matrix cb2b50979f67ed20aa9123ca02455011. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:56\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mYou got feature values that are out of the range: (0, 1). The feature values will cutoff to fit in the range (0, 1).\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:56\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 74 on test matrix bd72f652b06c4065a78377932d6d52c1  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:33:56\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:02\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 74 evaluation on test matrix bd72f652b06c4065a78377932d6d52c1 completed.\n",
      "\u001b[32m2021-09-20 16:34:02\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 74 on train matrix cb2b50979f67ed20aa9123ca02455011  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:02\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 74 evaluation on train matrix cb2b50979f67ed20aa9123ca02455011 completed.\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [e0a5d71bd6ef81449eaca3481ab4dd33] on train matrix cb2b50979f67ed20aa9123ca02455011\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 75, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 75: triage.component.catwalk.baselines.rankers.PercentileRankOneFeature({'descend': False, 'feature': 'project_features_entity_id_all_total_asking_price_sum'}) [e0a5d71bd6ef81449eaca3481ab4dd33] on train matrix cb2b50979f67ed20aa9123ca02455011. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 75 on test matrix bd72f652b06c4065a78377932d6d52c1  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 73 evaluation on test matrix bd72f652b06c4065a78377932d6d52c1 completed.\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 73 on train matrix cb2b50979f67ed20aa9123ca02455011  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:03\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 73 evaluation on train matrix cb2b50979f67ed20aa9123ca02455011 completed.\n",
      "\u001b[32m2021-09-20 16:34:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 75 evaluation on test matrix bd72f652b06c4065a78377932d6d52c1 completed.\n",
      "\u001b[32m2021-09-20 16:34:04\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 75 on train matrix cb2b50979f67ed20aa9123ca02455011  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:04\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 75 evaluation on train matrix cb2b50979f67ed20aa9123ca02455011 completed.\n",
      "\u001b[32m2021-09-20 16:34:04\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 9, failures: 0\n",
      "\u001b[32m2021-09-20 16:34:05\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallelizable batch train/testing with 3 tasks, 1 processes\n",
      "\u001b[32m2021-09-20 16:34:05\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [4b4888587f5f00326b03330f9bf94f27] on train matrix 96b224b8e1497f77156ae38a0250aa73\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:05\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 76, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:05\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 76: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [4b4888587f5f00326b03330f9bf94f27] on train matrix 96b224b8e1497f77156ae38a0250aa73. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:05\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 76 on test matrix 43e540def2000416c6b4bc020e4921f7  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:05\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:07\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 76 evaluation on test matrix 43e540def2000416c6b4bc020e4921f7 completed.\n",
      "\u001b[32m2021-09-20 16:34:07\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 76 on train matrix 96b224b8e1497f77156ae38a0250aa73  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:07\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:07\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 76 evaluation on train matrix 96b224b8e1497f77156ae38a0250aa73 completed.\n",
      "\u001b[32m2021-09-20 16:34:07\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [7cb8766191f08f9be157108e316a2b5e] on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:08\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 77, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:08\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 77: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [7cb8766191f08f9be157108e316a2b5e] on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:08\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 77 on test matrix 690f1ba2c18295a38c06c378f3ec1cdb  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:08\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:09\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 77 evaluation on test matrix 690f1ba2c18295a38c06c378f3ec1cdb completed.\n",
      "\u001b[32m2021-09-20 16:34:09\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 77 on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:09\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:09\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 77 evaluation on train matrix 3ba0ca70dcc92f9736ef5e8b97f9737b completed.\n",
      "\u001b[32m2021-09-20 16:34:09\u001b[0m - \u001b[1;30mVERBOSE\u001b[0m \u001b[34mTraining sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [1b6211da1dc10d85304f4ff05a4a1a20] on train matrix cb2b50979f67ed20aa9123ca02455011\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:10\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mModel 78, not found from previous runs. Adding the new model\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:10\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTrained model id 78: sklearn.ensemble.RandomForestClassifier({'max_depth': 50, 'min_samples_split': 25, 'n_estimators': 150}) [1b6211da1dc10d85304f4ff05a4a1a20] on train matrix cb2b50979f67ed20aa9123ca02455011. \u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:10\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 78 on test matrix bd72f652b06c4065a78377932d6d52c1  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:10\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:11\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 78 evaluation on test matrix bd72f652b06c4065a78377932d6d52c1 completed.\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mPredictions for model 78 on train matrix cb2b50979f67ed20aa9123ca02455011  weren't written to the db because, because you asked not to do so\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30m NOTICE\u001b[0m \u001b[35mNo bias audit configuration is available, so protected groups were not created: returning an empty data frame\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Model 78 evaluation on train matrix cb2b50979f67ed20aa9123ca02455011 completed.\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 3, failures: 0\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Starting parallelizable batch train/testing with 0 tasks, 2 processes\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30m   INFO\u001b[0m Done. successes: 0, failures: 0\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mTraining, testing and evaluatiog models completed\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mAll matrices that were supposed to be build were built. Awesome!\u001b[0m\n",
      "\u001b[32m2021-09-20 16:34:12\u001b[0m - \u001b[1;30mSUCCESS\u001b[0m \u001b[1;32mAll models that were supposed to be trained were trained. Awesome!\u001b[0m\n",
      "CPU times: user 3.73 s, sys: 1.24 s, total: 4.97 s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8910a7a791c557bf549f4445916eeea7'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"select run_hash from triage_metadata.triage_runs order by start_time desc limit 1;\"\n",
    "\n",
    "experiment_hash = pd.read_sql(q, conn)['run_hash'].iloc[0]\n",
    "experiment_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012-11-01'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "    select \n",
    "        to_char(max(train_end_time), 'YYYY-MM-DD') as last_time\n",
    "    from triage_metadata.experiment_models\n",
    "    join triage_metadata.models using(model_hash)\n",
    "    where experiment_hash = '{experiment_hash}'\n",
    "\"\"\".format(experiment_hash=experiment_hash)\n",
    "\n",
    "last_train_end_time = pd.read_sql(q, conn)['last_time'].iloc[0]\n",
    "last_train_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_type</th>\n",
       "      <th>metric</th>\n",
       "      <th>parameter</th>\n",
       "      <th>best_value</th>\n",
       "      <th>worst_value</th>\n",
       "      <th>stochastic_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>sklearn.tree.DecisionTreeClassifier</td>\n",
       "      <td>precision@</td>\n",
       "      <td>15_pct</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.439785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74</td>\n",
       "      <td>triage.component.catwalk.estimators.classifier...</td>\n",
       "      <td>precision@</td>\n",
       "      <td>15_pct</td>\n",
       "      <td>0.440860</td>\n",
       "      <td>0.279570</td>\n",
       "      <td>0.378495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>triage.component.catwalk.baselines.rankers.Per...</td>\n",
       "      <td>precision@</td>\n",
       "      <td>15_pct</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>sklearn.ensemble.RandomForestClassifier</td>\n",
       "      <td>precision@</td>\n",
       "      <td>15_pct</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.419355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_id                                         model_type      metric  \\\n",
       "0        73                sklearn.tree.DecisionTreeClassifier  precision@   \n",
       "1        74  triage.component.catwalk.estimators.classifier...  precision@   \n",
       "2        75  triage.component.catwalk.baselines.rankers.Per...  precision@   \n",
       "3        78            sklearn.ensemble.RandomForestClassifier  precision@   \n",
       "\n",
       "  parameter  best_value  worst_value  stochastic_value  \n",
       "0    15_pct    0.677419     0.161290          0.439785  \n",
       "1    15_pct    0.440860     0.279570          0.378495  \n",
       "2    15_pct    0.451613     0.451613          0.451613  \n",
       "3    15_pct    0.419355     0.419355          0.419355  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "    select \n",
    "        model_id, model_type, metric, parameter, best_value, worst_value, stochastic_value\n",
    "    from triage_metadata.experiment_models\n",
    "    join triage_metadata.models using(model_hash)\n",
    "    join test_results.evaluations using(model_id)\n",
    "    where experiment_hash = '{experiment_hash}' and train_end_time='{last_split}' \n",
    "    and metric='precision@' and parameter='15_pct'\n",
    "\"\"\".format(\n",
    "    experiment_hash = experiment_hash,\n",
    "    last_split=last_train_end_time\n",
    ")\n",
    "\n",
    "evals = pd.read_sql(q, conn)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "triage-demo",
   "language": "python",
   "name": "triage-demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
